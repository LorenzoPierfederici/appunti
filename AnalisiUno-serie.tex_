%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\chapter{serie}

Data una successione $a_n$ di numeri reali o complessi
possiamo considerare la successione
delle cosiddette \myemph{somme parziali}
\[
  S_n = \sum_{k=0}^{n} a_k.
\]
Potremo scrivere più concisamente $S_n = \sum a_n$.
I numeri $a_n$ si chiamano \myemph{termini della serie}
La serie si dirà convergente, divergente o indeterminata se la
successione delle somme parziale è convergente, divergente o indeterminata.
Se la successione delle somme parziali ammette limite il limite viene chiamato
\myemph{somma della serie} e si indica con
\[
  \sum_{k=0}^{+\infty} a_k = \lim_{n\to +\infty} S_n = \lim_{n\to+\infty} \sum_{k=0}^n a_k.
\]

La terminologia già introdotta per le successioni si applica anche alle
serie che sono in effetti anch'esse delle successioni.
In particolare una serie può essere convergente, divergente o indeterminata.
Questo si chiama il \myemph{carattere della serie}.

\begin{example}[la serie geometrica]
Fissato $q \in \RR$ alla successione (cosiddetta geometrica)
\[
  a_n = q^n
\]
di termini
\[
  a_0 = 1,\qquad
  a_1 = q,\qquad
  a_2 = q^2,\qquad
  a_3 = q^3, \dots
\]
è associata la \myemph{serie geometrica}
\[
  S_n = \sum_{k=0}^{n} q^n
\]
le cui somme parziali sono
\begin{align*}
  S_0 &= 1, \\
  S_1 &= 1 + q, \\
  S_2 &= 1 + q + q^2, \\
  &\quad\vdots
\end{align*}
\end{example}

Il seguente teorema ci mostra come per diversi valori di $q$
la serie geometrica assume
tutti i caratteri: convergente, divergente, indeterminato.

\begin{theorem}[somma della serie geometrica]
\mymargin{somma della serie geometrica}
Sia $q\in \RR$. Se $q\neq 1$ si ha
\[
 \sum_{k=0}^n q^k  = \frac{1-q^{n+1}\!\!\!\!\!\!}{1-q}.
\]
Se $\abs{q} < 1$ la serie geometrica converge:
\[
 \sum_{k=0}^{+\infty} q^n = \frac{1}{1-q}
\]
se $q\ge 1$ diverge:
\[
 \sum_{k=0}^{+\infty} q^n = +\infty
\]
e se $q\le -1$ la serie geometrica è indeterminata.
\end{theorem}
%
\begin{proof}
Il primo risultato riguarda una somma finita.
Si ha
\[
  (1-q)\cdot \sum_{k=0}^n q^k
  = \sum_{k=0}^n q^k - q \cdot \sum_{k=0}^n q^k
  = \sum_{k=0}^n q^k - \sum_{k=1}^{n+1} q^k
  = 1 - q^{n+1}
\]
da cui si ottiene, se $q\neq 1$, il primo risultato.

Passando al limite per $n\to +\infty$, se $\abs{q} < 1 $
si nota che $q^{n+1} \to 0$ e la serie converge a $1/(1-q)$
mentre se $q>1$ osserviamo che
$q^n\to +\infty$ e quindi la serie diverge a $+\infty$ (infatti in questo
caso $1-q$ è negativo).
Se $q=1$ si ha $q^k=1$ e quindi $\sum_{k=0}^n q^k = n+1 \to +\infty$.

Se $q<0$ si ha $q= -\abs{q}$ da cui
\[
 \sum_{k=0}^n q^k
 = \frac{1-q^{n+1}\!\!\!\!\!}{1-q}
 = \frac{1-(-1)^{n+1}\abs{q}^{n+1}}{1+\abs{q}}.
 \]
 Se $q=-1$ si ha
 \[
   \sum_{k=0}^n q^k = \sum_{k=0}^n (-1)^k
   =
     \begin{cases}
      1 & \text{se $n$ è pari}\\
      0 & \text{se $n$ è dispari}
     \end{cases}
 \]
 e quindi la serie è indeterminata.
Se $q<-1$ si osserva che sui termini dispari
si ha $(-1)^{n+1}\abs{q}^{n+1}\to +\infty$ mentre sui
termini pari tale quantità tende a $-\infty$.
Lo stesso vale per le somme parziali della serie che quindi
è, anche in questo caso, indeterminata.
\end{proof}

\begin{theorem}[linearità della somma]
\mymargin{linearità della somma infinita}
Se $\sum a_n$ e $\sum b_n$ sono convergenti
allora per ogni $\lambda,\mu\in \CC$
anche $\sum (\lambda a_n + \mu b_n)$ è convergente
e si ha
\[
 \sum_{k=0}^{+\infty} (\lambda a_n + \mu b_n)
 = \lambda \sum_{k=0}^{+\infty} a_n  + \mu \sum_{k=0}^{+\infty} b_n.
\]
\end{theorem}
%
\begin{proof}
Se $S_n$ e $R_n$ sono le somme parziali delle serie $\sum a_n$ e $\sum b_n$
allora le somme parziali della serie $\sum (\lambda a_n + \mu b_n)$ sono
$\lambda S_n + \mu R_n$ (in quanto sulle somme finite vale la proprietà distributiva e commutativa). Ma se $S_n \to S$ e $R_n \to R$ allora
$\lambda S_n + \mu R_n \to \lambda S + \mu R$.
\end{proof}

Osserviamo che le serie (così come le successioni) formano uno spazio
vettoriale in cui le operazioni di somma e prodotto per scalare vengono
eseguite termine a termine: $\sum a_n + \sum b_n = \sum (a_n + b_n)$,
$\lambda \sum a_n = \sum (\lambda a_n)$.
Il teorema precedente ci dice allora che le serie (così come le successioni)
convergenti sono un sottospazio vettoriale e che la somma della serie (così come il limite della successione) è un'operatore lineare definito su tale sottospazio.

\begin{theorem}[condizione necessaria per la convergenza]
\mymargin{condizione necessaria per la convergenza}
Se la serie $\sum a_n$ converge allora $a_n \to 0$.
\end{theorem}
%
\begin{proof}
Se la serie $\sum a_n$ converge significa che le somme parziali
$S_n = \sum_{k=0}^n a_k$ convergono: $S_n \to S$. Ma allora
\[
  a_n = S_n - S_{n-1} \to S - S = 0.
\]
\end{proof}

\begin{theorem}[serie che differiscono su un numero finito di termini]
\mymargin{serie che differiscono su un numero finito di termini}
Se le due successioni $a_n$ e $b_n$ differiscono solo su un numero finito
di termini, allora le serie corrispondenti $\sum a_n$ e $\sum b_n$ hanno lo stesso carattere.
\end{theorem}
%
\begin{proof}
Se le successioni differiscono su un numero finito di termini significa
che esiste un $N\in \NN$ tale che per ogni $k>N$ si ha $a_k=b_k$.
Dunque se indichiamo con $S_n = \sum_{k=0}^n a_k$ e $R_n = \sum_{k=0}^n b_k$
le corrispondenti successioni delle somme parziali, si avrà per ogni $n>N$
\[
  S_n - R_n
    = \sum_{k=0}^n a_k - \sum_{k=0}^n b_k
    = \sum_{k=0}^N (a_k - b_k) = C
\]
dove $C$ è una costante indipendente da $n$. Dunque
\[
  S_n = R_n + C.
\]
Se il limite di $R_n$ non esiste allora non esiste neanche il limite
di $S_n$ (altrimenti essendo $R_n = S_n -C$ anche il limite di $R_n$ dovrebbe esistere). Se il limite di $R_n$ è infinito allora il limite di $S_n$ è uguale
al limite di $R_n$. E se il limite di $R_n$ è finito anche il limite di $S_n$ è finito.

Dunque il carattere della successione $S_n$ è lo stesso della successione $R_n$
cioè le due serie hanno lo stesso carattere.
\end{proof}

Come per le successioni potremo considerare serie il cui primo termine ha un indice diverso da $0$. Ci si potrà sempre ricondurre (con un cambio di variabile)
ad una serie il cui indice parte da zero. Ad esempio
(facendo il cambio di variabile $j=k-1$ da cui $j=0$ quando $k=1$
e ricordando che l'indice utilizzato nelle somme delle
serie è una variabile muta):
\[
 \sum_{k=1}^{+\infty} \frac{1}{2^k}
 = \sum_{j=0}^{+\infty} \frac{1}{2^{j+1}}
 = \sum_{k=0}^{+\infty} \frac{1}{2^{k+1}}.
\]

Si osservi inoltre che in base al teorema precedente quale sia il primo indice
da cui si comincia a sommare non è rilevante per quanto riguarda il carattere della serie.
Se però la serie è convergente la sua somma può variare, ad esempio:
\[
 \sum_{k=1}^{+\infty} \frac{1}{2^k} = \enclose{\sum_{k=0}^{+\infty} \frac{1}{2^k}} - 2^0.
\]

Nota bene: in molti libri si scrive $\infty$ al posto di $+\infty$.
Risulta quindi molto comune omettere il segno $+$ davanti a $\infty$
nella terminologia delle serie (e anche delle successioni) visto
che gli indici si intendono numeri naturali e quindi $-\infty$ non avrebbe
senso.

Ci sono però casi in cui può essere utile usare anche gli indici negativi,
ad esempio si potrebbe definire (ma non lo faremo):
\[
  \sum_{k=-\infty}^{+\infty} a_k
  = \sum_{k=0}^{+\infty} a_k +
  \sum_{k=-1}^{-\infty} a_k
  = \sum_{k=0}^{+\infty} a_k +
  \sum_{k=1}^{+\infty} a_{-k}
\]
quando $a_k$ è definita per ogni $k\in \ZZ$ e le due serie al lato destro
dell'uguaglianza esistono entrambe e non hanno somme infinite di segno opposto.

\begin{theorem}[coda di una serie convergente]
Sia $\sum a_n$ una serie convergente. Allora
\[
  \lim_{n\to +\infty} \sum_{k=n+1}^{+\infty} a_k = 0.
\]
\end{theorem}
%
\begin{proof}
Posto
\[
  S_n = \sum_{k=0}^n a_k,
\]
per definizione di serie convergente sappiamo che esiste $S$ finito
tale che $S_n \to S$. Osserviamo allora che
\[
  \sum_{k=n+1}^{+\infty} a_k = \lim_{N\to+\infty} \sum_{k=n+1}^N a_k
   = \lim_{N\to +\infty} S_N - S_n = S - S_n
\]
e, per $n\to +\infty$ si ha ovviamente $S - S_n \to S - S = 0$.
\end{proof}

\section{serie telescopiche}

Una serie scritta nella forma
% $\Sigma \Delta \vec a$ cioè
% del tipo:
\[
  \sum (a_{k} - a_{k+1})
\]
viene detta \emph{telescopica}\mymargin{serie telescopica}
in quanto i singoli termini della somma, come i tubi di un cannocchiale,
si semplificano uno con l'altro permettendo al cannocchiale di chiudersi:
\[
  \sum_{k=0}^n (a_{k} - a_{k+1})
  = \sum_{k=0}^{n} a_k - \sum_{k=1}^{n+1} a_k
  = a_0 - a_{n+1}.
\]

Ad esempio per calcolare la somma della serie geometrica
potevamo
sfruttare questa relazione
\[
  \frac{1-q^{n+1}}{1-q} - \frac{1-q^n}{1-q}
  = \frac{q^n - q^{n+1}}{1-q} = q^n \cdot \frac{1-q}{1-q} = q^n
\]

\begin{example}[serie di Mengoli]
Si ha
\[
  \sum_{n=1}^{+\infty} \frac{1}{n(n+1)} = 1.
\]
\end{example}
%
\begin{proof}
Infatti
\[
  \sum_{k=1}^n \frac{1}{k(k+1)}
  = \sum_{k=1}^n \enclose{\frac{1}{k} - \frac{1}{k+1}}
  = \sum_{k=1}^n \frac{1}{k} - \sum_{k=2}^{n+1} \frac{1}{k}
  = 1 - \frac{1}{n+1} \to 1.
\]
\end{proof}

\section{serie a termini positivi}

\index{serie a termini positivi}
Nel seguito considereremo serie i cui termini sono numeri reali
positivi (o almeno non negativi).
Quando scriveremo $a_n >0$ (o $a_n \ge 0$) sarà sempre
sottointeso che $a_n\in \RR$ visto che per i numeri complessi non
reali non abbiamo definito la relazione d'ordine.

\begin{theorem}[carattere delle serie a termini positivi]
\mymargin{carattere delle serie a termini positivi}
Se $a_n\ge 0$
la serie $\sum a_n$ non può essere indeterminata:
o converge oppure diverge a $+\infty$.
\end{theorem}
%
\begin{proof}
Se $a_n \ge 0$ essendo $a_n = S_n - S_{n-1}$ significa che
la successione $S_n$ delle somme parziali è crescente.
Dunque il limite delle $S_n$ esiste ed è in $(-\infty, +\infty]$.
\end{proof}

\begin{theorem}[criterio del confronto]
\mymargin{criterio del confronto}
Siano $\sum a_n$ e $\sum b_n$ serie a
termini positivi che si confrontano: $0\le a_n\le b_n$.
Allora
\[
  \sum_{k=0}^\infty a_n \le \sum_{k=0}^\infty b_n.
\]
In particolare se $\sum b_n$ converge anche $\sum a_n$ converge
e se $\sum a_n$ diverge anche $\sum b_n$ diverge.
\end{theorem}
%
\begin{proof}
Se $S_n$ sono le somme parziali di $\sum a_n$ e $R_n$ sono le somme
parziali di $\sum b_n$ si ha $S_n \le R_n$ e il risultato
si riconduce al confronto tra successioni.
\end{proof}

\begin{example}
La serie
\[
 \sum \frac{1}{k^2}
\]
è convergente.
Infatti osservando che si ha per ogni $n>0$
\[
  \frac{1}{(n+1)^2} \le \frac{1}{n(n+1)}
\]
possiamo affermare che
\[
  \sum_{k=1}^\infty \frac{1}{k^2}
  = 1 + \sum_{k=1}^\infty \frac{1}{(k+1)^2}
  \le 1+ \sum_{k=1}^\infty \frac{1}{k(k+1)}
  = 2
\]
in quanto ci siamo ricondotti alla
serie telescopica di Mengoli che ha somma pari a $1$.
\end{example}

\begin{definition}[equivalenza asintotica]
\index{equivalenza asintotica}
Due successioni a termini positivi $a_n$ e $b_n$ si dicono essere
\myemph{asintoticamente equivalenti} e si scrive $a_n \sim b_n$
se, per $n\to +\infty$
\[
  \frac{a_n}{b_n} \to 1.
\]
\end{definition}

\begin{corollary}[criterio del confronto asintotico]
\mymargin{criterio del confronto asintotico}
Se $a_n$ e $b_n$ sono successioni positive
asintoticamente equivalenti
allora le serie corrispondenti $\sum a_n$ e $\sum b_n$
hanno lo stesso carattere.
\end{corollary}
%
\begin{proof}
Le serie a termini positivi non possono essere indeterminate
quindi è sufficiente verificare che se una serie converge, converge anche l'altra.
Essendo $a_n / b_n$ convergente tale rapporto deve anche essere
limitato, quindi esiste $C\in \RR$ tale che
\[
   a_n \le C \cdot b_n.
\]
Se la serie $\sum b_n$ converge anche $\sum C \cdot b_n$ converge e, per confronto,
converge anche $\sum a_n$.

Viceversa, scambiando il ruolo di $a_n$ e $b_n$ si verifica che se $a_n$
converge, converge anche $b_n$.
\end{proof}

\begin{example}
La serie
\[
\sum_n \frac{n^2+2n+3}{2n^4-n^3+n+1}
\]
è convergente. Infatti si può facilmente verificare che
\[
   \frac{n^2+2n+3}{2n^4-n^3+n+1} \sim \frac{1}{2n^2}.
\]
Ma sappiamo che la serie $\sum 1/n^2$ è convergente, di conseguenza
anche la serie $\sum 1/(2n^2)$ lo è (per linearità della somma)
e quindi, per confronto
asintotico, anche la serie data è convergente.
\end{example}

\begin{theorem}[criterio della radice]
\mymargin{criterio della radice}
Sia $\sum a_n$ una serie a termini non negativi
(cioè $a_n\ge 0$) tale che
$\sqrt[n]{a_n} \to \ell \in [0,+\infty]$.
Se $\ell<1$ allora la serie converge.
Se $\ell>1$ allora la serie diverge.
\end{theorem}
%
\begin{proof}
Nel caso $\ell < 1$
prendiamo $q$ con $\ell < q < 1$ e poniamo $\eps = q-\ell$.
Per la definizione di limite $\sqrt[n]{a_n}\to \ell$ sappiamo
esistere $N$ tale che per ogni $n > N$ si abbia
\[
  \sqrt[n]{a_n} < \ell + \eps = q
\]
cioè
\[
   a_n < q^n.
\]
Sapendo che $\sum q^n$ converge, sapendo anche che il carattere
della serie non cambia modificando un numero finito di termini,
per confronto possiamo concludere che anche la serie $\sum a_n$ converge.

Il caso $\ell > 1$ si tratta in maniera analoga.
\end{proof}

\begin{example}
La serie
\[
  \sum_k 2^{(\ln k) - k}
\]
è convergente. Infatti si ha
\[
 \sqrt[k]{2^{\ln k - k}}
 = 2^{\frac{\ln k - k}{k}}
 = 2^{\frac{\ln k }k - 1}
 \to 2^{-1}
 = \frac{1}{2}
 < 1.
\]
\end{example}

\begin{theorem}[criterio del rapporto]
\mymargin{criterio del rapporto}
Sia $\sum a_n$ una serie a termini positivi
tale che $a_{n+1} / a_n \to \ell \in [0,+\infty]$.
Se $\ell <1$ allora la serie converge.
Se $\ell > 1$ la serie diverge.
\end{theorem}
%
\begin{proof}
Per il criterio del rapporto alla Cesàro si ha $\sqrt[n]{a_n} \to \ell$
quindi ci riconduciamo al criterio della radice.
\end{proof}

\begin{example}
Per ogni $x\ge 0$ la serie
\[
  \sum \frac{x^n}{n!}
\]
converge.
\end{example}
%
\begin{proof}
Applichiamo il criterio del rapporto. Posto $a_n = x^n / n!$ si ha
\[
\frac{a_{n+1}}{a_n}
= \frac{x^{n+1}}{(n+1)!}\cdot \frac{n!}{x^n}
= \frac{x}{n+1} \to 0 < 1.
\]
Dunque la serie converge.
\end{proof}

Osserviamo invece che il criterio del rapporto non si applica alla
\myemph{serie armonica}
\[
  \sum_k \frac{1}{k}
\]
in quanto
\[
 \frac{\frac{1}{k+1}}{\frac{1}{k}}
 = \frac{k}{k+1} \to 1.
\]

Per capire se la serie armonica converge o diverge presentiamo il metodo
di \emph{condensazione} che verrà enunciato in generale nel prossimo teorema
ma che può essere meglio compreso se applicato al caso particolare
della serie armonica.

Mostreremo che la serie armonica diverge.
L'idea è semplicemente quella di raggruppare gli addendi della serie armonica
in gruppi di lunghezza potenze di due e stimare ogni gruppo dal basso
con il termine più piccolo (cioè l'ultimo) di ogni gruppo:
\begin{align*}
 \sum_{k=1}^\infty \frac{1}{k}
 & = 1 + \frac 1 2
     + \enclose{\frac 1 3 + \frac 1 4}
     + \enclose{\frac 1 5 + \frac 1 6 + \frac 1 7 + \frac 1 8}
     + \dots\\
 & > 1 + \frac 1 2 + 2 \cdot \frac 1 4 + 4 \cdot \frac 1 8 + \dots \\
   & = 1 + \frac 1 2 + \frac 1 2 + \frac 1 2 + \dots
    = +\infty.
\end{align*}

\begin{theorem}[criterio di condensazione di Cauchy]
\mymargin{criterio di condensazione di Cauchy}
Sia $a_n$ una successione decrescente di numeri reali non negativi:
$a_n \ge 0$.
Allora la serie $\sum a_k$ converge se e solo se converge
la serie
\[
  \sum 2^k a_{2^k}.
\]
\end{theorem}
%
\begin{proof}
Supponiamo per comodità che le somme partano da $k=1$.
Si tratta di raggruppare i termini $a_k$ in gruppi di potenze di due:
\begin{align*}
  &a_1, \\
  &a_2,\ a_3, \\
  &a_4,\ a_5,\ a_6,\ a_7, \\
  &a_8,\ a_9,\ a_{10},\ \dots,\ a_{15}, \\
  &\vdots\\
  &a_{2^n},\ a_{2^n+1},\ \dots,a_{2^{n+1}-1},\\
  &\vdots
\end{align*}
Posto $S_n = \sum_{k=1}^n a_k$,
sommando i termini delle prime $N$ righe si osserva quindi che:
\[
  S_{2^N-1}
  = \sum_{k=1}^{2^N-1} a_k
  = \sum_{n=0}^{N-1}\,\, \sum_{j=0}^{2^n-1} a_{2^k+j}
\]
Visto che la successione $a_k$ è decrescente i termini di ogni gruppo si
possono stimare dall'alto e dal basso con il primo e l'ultimo termine:
\[
  a_{2^n} \ge a_{2^n+1} \ge \dots \ge a_{2^{n+1}-1} \ge a_{2^{n+1}}
\]
e quindi
\[
\sum_{n=0}^{N-1} 2^n a_{2^{n+1}}
\le S_{2^N-1}
\le \sum_{n=0}^{N-1} 2^n a_{2^n}.
\]

Dunque se la serie $\sum 2^n a_{2^n}$ converge allora la sottosuccessione
di somme parziali $S_{2^N-1}$ è superiormente limitata: $S_{2^N-1}\le C$.
Essendo $a_k \ge 0$ la successione $S_k$ è crescente.
Ma allora l'intera
successione $S_k$ è limitata
perché per ogni $k\in \NN$ esiste $N\in \NN$ tale che $k\le 2^N-1$ per cui
$S_k \le S_{2^N-1} \le C$.
Visto che $S_k$ è crescente $S_k$ ha limite e visto che abbiamo
appena verificato che $S_k$ è limitata allora il limite è finito
e la serie è convergente.

Viceversa se la serie $\sum a_k$ converge significa che
$S_k$ converge e dunque anche la sottosuccessione
$S_{2^N}$ converge e di conseguenza esiste
$C\in \RR$ tale che per ogni $N \in \NN$:
 $S_{2^N-1}\le C$.
Ma allora
\[
  \sum_{n=0}^{N-1} 2^n a_{2^n}
  = \frac 1 2 \sum_{n=0}^{N-1} 2^{n+1} a_{2^n}
  \le \frac 1 2 S_{2^N-1}
  \le \frac 1 2 C.
\]
e dunque anche la serie $\sum 2^n a_{2^n}$ risulta essere limitata e
di conseguenza (essendo una serie a termini positivi) è convergente.
\end{proof}


\begin{exercise}
Utilizzare il criterio di condensazione per dimostrare che la serie
\[
  \sum \frac{1}{n \cdot \ln n}
\]
diverge.
\end{exercise}


\begin{corollary}[serie armonica generalizzata]
\mymargin{serie armonica generalizzata}
La serie
\[
 \sum_n \frac{1}{n^\alpha}
\]
converge se $\alpha>1$,
diverge se $0\le \alpha\le 1$.
\end{corollary}
%
\begin{proof}
Applichiamo il criterio di condensazione. Posto $a_n = 1/n^\alpha$ Si ha
\[
  \sum_n 2^n a_{2^n} = \sum_n 2^n \frac{1}{(2^n)^\alpha}
  = \sum_n 2^{n(1-\alpha)}
  = \sum_n \enclose{2^{(1-\alpha)}}^n
\]
che è una serie geometrica di ragione $q=2^{1-\alpha}$.
Se $\alpha>1$ allora $q<1$ e la serie armonica è convergente
se invece $\alpha \le $ allora $q\ge 1$ e la serie
armonica è divergente.
\end{proof}

\section{convergenza assoluta}

Per le serie a termini positivi abbiamo molti criteri di convergenza
che invece, in generale, non si applicano alle serie di segno qualunque
o alle serie di numeri complessi.
La convergenza di queste ultime, però, può a volte ricondursi
facilmente
alla
convergenza delle serie a termini positivi, passando al modulo
ogni termine.

\begin{definition}[convergenza assoluta]
Diremo che una serie (a termini reali o complessi) $\sum a_n$
è \myemph{assolutamente convergente} se la serie $\sum \abs{a_n}$
è convergente.
\end{definition}

\begin{theorem}[convergenza assoluta]
Se una serie $\sum a_n$ (reale o complessa)
è assolutamente convergente allora è convergente e vale
\[
  \abs{\sum_{k=0}^\infty a_k} \le \sum_{k=0}^\infty \abs{a_k}.
\]
\end{theorem}
%
\begin{proof}
Supponiamo inizialmente che gli $a_n$ siano numeri reali.
Definiamo $a_n^+ = \max\{0, a_n\}$ e $a_n^- = -\min \{0, a_n\}$.
Cioè se $a_n\ge 0$ si ha $a_n^+ = a_n$ e $a_n^-=0$ se invece $a_n\le 0$
si ha $a_n^+ =0$ e $a_n^- = -a_n$.
Dunque $a_n^+\ge 0$, $a_n^-\ge 0$ e
\[
   a_n = a_n^+  - a_n^-
   \qquad\text{e}\qquad
   \abs{a_n} = a_n^+ + a_n^-.
\]
Allora se $\sum \abs{a_n}$ converge,
per confronto anche $\sum a_n^+$ e $\sum a_n^-$ convergono.
Dunque, per il teorema sulla somma dei limiti,
$\sum a_n = \sum a_n^+ - \sum a_n^-$
e quindi anche $\sum a_n$ converge.

Se abbiamo una successione di complessi $a_n = x_n + i y_n$
e se
$\sum \abs{a_n}$ converge allora, per confronto,
anche $\sum \abs{x_n}$ e $\sum\abs{y_n}$ convergono
(si osservi infatti che $\abs{x} \le \abs{x+iy}$ e $\abs{y}\le \abs{x+iy}$).
Dunque $\sum x_n$ e $\sum y_n$ convergono per quanto
già dimostrato sulle serie a termini reali.
Ma allora anche $\sum i y_n$ e $\sum a_n = \sum (x + iy_n)$ convergono.

Poniamo ora
\[
  S_n  = \sum_{k=0}^n a_k.
\]
Per la convessità del modulo sappiamo che (essendo la somma finita)
\[
 \abs{S_n} \le \sum_{k=0}^n \abs{a_k} \le \sum_{k=0}^{+\infty} \abs{a_k}.
\]
E per continuità del modulo, posto $S= \lim S_n$ si ha
\[
  \abs{\sum_{k=0}^{+\infty} a_k}
  = \abs{S}
  = \lim_{n\to +\infty} \abs{S_n}
  \le \sum_{k=0}^{+\infty} \abs{a_k}.
\]
\end{proof}

\begin{theorem}[riordinamento delle serie assolutamente convergenti]
Se $\sum a_n$ è una serie assolutamente convergente e $\sigma\colon \NN \to \NN$
è una qualunque funzione biettiva (permutazione dei numeri naturali)
si ha
\[
  \sum_{n=0}^{+\infty} a_n = \sum_{n=0}^{+\infty} a_{\sigma(n)}.
\]
\end{theorem}
%
\begin{proof}
Posto
\[
  S_n = \sum_{k=0}^n a_k
  \qquad\text{e}\qquad
  R_n = \sum_{k=0}^{n} a_{\sigma(k)}
\]
consideriamo, per ogni $n\in \NN$ il più grande numero
$m_n\in \NN$ tale per cui
l'insieme di indici $A_n = \{ \sigma(0), \sigma(1), \dots, \sigma(n)\}$
contiene l'insieme dei primi $m_n$ naturali $\{0, 1, \dots, m_n -1 \}$.
Formalmente si può definire
\[
  m_n = \min (\NN \setminus A_n).
\]

Osserviamo che $m_n\to +\infty$ perché altrimenti ci sarebbero dei
numeri naturali che non vengono mai assunti dalla successione $\sigma(k)$.

Allora si osserva che ogni addendo nella somma che definisce
$S_{m_n}$ è presente anche
nella somma che definisce $R_n$ e quindi
facendo la differenza $R_n - S_{m_n}$ si ottiene la somma di tutti
gli $a_{\sigma(k)}$ per $k=0,\dots,n$ tali che $\sigma(k) > m_n$.
Dunque, stimando il valore assoluto della somma con la somma dei valori
assoluti e aggiungendo alla somma anche tutti gli altri valori $a_k$ con $k>m_n$, si ottiene:
\begin{align*}
\abs{R_n - S_{m_n}}
\le \sum_{k=m_n}^\infty \abs{a_k}.
\end{align*}
Ma, essendo la serie $\sum a_k$ assolutamente convergente, la coda della serie dei valori assoluti tende a zero e quindi anche la sottosuccessione
delle code che partono dall'indice $m_n$ tende a zero (cambio di variabile
nel limite). Dunque
\[
  \lim_{n\to +\infty} R_n - S_{m_n} = 0.
\]
D'altra parte $S_n\to S$ dove $S$ è la somma della serie convergente
$\sum a_k$ e di conseguenza anche $S_{m_n} \to S$.
Dunque si ottiene, come volevamo dimostrare:
\[
 R_n = (R_n - S_{m_n}) + S_{m_n} \to 0 + S = S.
\]
\end{proof}

\begin{theorem}[associatività delle serie convergenti]
Se $\sum a_k$ è una serie, scelta comunque
una successione crescente $k_n$ con $k_0=0$
possiamo considerare la serie $\sum b_n$
i cui termini
\[
  b_n = \sum_{j=k_n}^{k_{n+1}-1} a_k
\]
si ottengono associando i termini di $a_k$ a gruppi
consecutivi delimitati dalla successione di indici
$k_n$.

Se la serie $\sum a_k$ non è indeterminata
allora neanche la serie $\sum b_n$ è indeterminata e si ha
\[
\sum_{n=0}^{+\infty} b_n
= \sum_{k=0}^{+\infty} a_k.
\]

Inoltre se $\sum a_k$ è a termini positivi e se
$\sum b_n$ è convergente, anche $\sum a_n$ è convergente.
\end{theorem}
%
\begin{proof}
Siano $S_k = \sum_{j=0}^k a_j$ le somme parziali della
serie $\sum a_j$. Allora le somme parziali della serie $\sum b_n$
non sono altro che la sottosuccessione $S_{k_n}$.
Dunque se $S_k$ converge anche ogni sua sottosuccessione
converge allo stesso limite. Si ottiene dunque
la prima parte del teorema.

Se inoltre $a_k \ge 0$, entrambe le serie sono a termini positivi
e quindi entrambe ammettono limite. Ma visto che le somme parziali
della seconda serie sono una sottosuccessione delle somme
parziali della prima serie, anche in questo caso i due limiti
devono coincidere e se una delle due serie è convergente
anche l'altra lo è.
\end{proof}


\section{le serie di potenze}



Se $a_k$ è una successione di numeri complessi, la serie
\[
 \sum a_k z^k
\]
dipendente da un parametro $z$ si chiama \myemph{serie di potenze}
di coefficienti $a_k$.
Se chiamiamo $A\subset \CC$ l'insieme dei numeri complessi $z$
per i quali la serie di potenze converge, si otterrà una funzione
$f \colon A \to \CC$ definita da
\[
  f(z) = \sum_{k=0}^{+\infty} a_k z^k.
\]

\begin{example}[la serie geometrica]
La serie di potenze di coefficienti $a_k=1$ è la
serie geometrica $\sum z^k$
che risulta essere convergente (almeno) sul cerchio $\abs{z} < 1$.
Su tale cerchio si ha
\[
 f(z) = \sum_{k=0}^{+\infty} z^k  = \frac{1}{1-z}.
\]
\end{example}

\begin{theorem}[raggio di convergenza]
Se la serie di potenze $\sum a_k z^k$ converge in un punto $z_0\in \CC$ allora converge assolutamente per ogni $z$ tale che $\abs{z}< \abs{z_0}$.
Viceversa, se la serie non converge in un punto $z_0\in \CC$ allora
non converge in nessun $z$ tale che $\abs{z} > \abs{z_0}$.
\end{theorem}
%
\begin{proof}
Se la serie $\sum a_k z_0^k$ converge significa che la successione
$a_k z_0^k$ è infinitesima e in particolare è limitata.
Esiste dunque $M$ tale che per ogni $k\in \NN$
\[
 \abs{a_k z_0^k} \le M
\]
e posto $R = \abs{z_0}$ si ha dunque
\[
 \abs{a_k} \le \frac{M}{\abs{z_0}^k}.
\]
Scelto ora qualunque $z\in \CC$ con $\abs{z} < \abs{z_0}$ si ha
\[
  \abs{a_k z^k} \le \abs{a_k}\cdot \abs{z}^k \le M \frac{\abs{z}^k}{\abs{z_0}^k}
  \le M q^k
\]
dove abbiamo posto $q = \abs{z}/ \abs{z_0}$.
Essendo $q<1$ la serie geometrica $\sum q^k$ converge e, per confronto
anche la serie $\sum \abs{a_k z^k}$ converge. Dunque la serie $\sum a_k z^k$ converge assolutamente.

Viceversa supponiamo che $\sum a_k z_0^k$ non converga e prendiamo $z$ con $\abs{z} > \abs{z_0}$.
Allora $\sum a_k z^k$ non può convergere perché se  convergesse allora per il punto precedente la serie $\sum a_k z_0^k$ dovrebbe anch'essa convergere.
\end{proof}


\begin{comment}

\section{la serie esponenziale}

Definiamo la funzione $\exp \colon \CC \to \CC$
\mymargin{$\exp z$}
come
\[
\exp(z) = \sum_{k=0}^\infty \frac{z^k}{k!}.
\]
Abbiamo già osservato che (grazie al criterio del rapporto)
la serie converge assolutamente per ogni $z \in \CC$, dunque
la funzione $\exp$ è ben definita.
Vedremo in questo capitolo che la definizione data sopra coincide con
la definizione di esponenziale
\[
e^z = \lim_{n\to +\infty}\enclose{1 + \frac 1 n}^n
\]
data nel capitolo sui numeri complessi che a sua volta coincide con
la potenza $e^x$ definita nel capitolo sui numeri reali.
Anzi, il seguente teorema giustifica l'esistenza del limite nella
definizione di $e^z$ (questione che avevamo lasciato in sospeso).

\begin{theorem}[collegamento tra le due definizioni di esponenziale]
\mymargin{collegamento tra le due definizioni di esponenziale}
Per ogni $z\in \CC$ la successione
$  \enclose{1+\frac z n}^n $
è convergente
e si ha
\[
  \lim_{n \to +\infty} \enclose{1+\frac z n}^n  = \sum_{k=0}^\infty \frac{z^k}{k!}.
\]
\end{theorem}
%
\begin{proof}
Utilizzando lo sviluppo del binomio osserviamo che si ha
\[
 \enclose{1+\frac z n}^n
 = \sum_{k=0}^n \binom{n}{k} \frac{z^k}{n^k}
 = \sum_{k=0}^n \frac{z^k}{k!} \cdot \frac{n!}{n^k\cdot (n-k)!}.
\]
Posto per ogni $k\le n$
\begin{align*}
 c(n,k)
  &= \frac{n!}{n^k\cdot (n-k)!}
  = \frac{n \cdot (n-1) \cdot \ldots \cdot(n-k)}{n^k} \\
  &= \frac{n}{n}\cdot {\frac {n-1} n} \cdot \frac {n-2} {n} \cdot \ldots \cdot \frac{n-k}{n}
\end{align*}
osserviamo che $0\le c(n,k)\le 1$ in quanto
prodotto di numeri non negativi minori o uguali ad $1$.
Inoltre, fissato $k$, si ha $c(n,k)  \to 1$ per $n\to +\infty$
in quanto ogni fattore $\frac{n-j}{n}$ tende
a $1$ per $n\to +\infty$ (si noti che a $k$ fissato il numero di fattori $k$ è
fissato).


Sia $z\in \CC$ fissato e sia
\[
  S_M = \sum_{k=0}^{M} \frac{\abs{z}^k}{k!}.
\]
Abbiamo già osservato che $S_M$ converge per $M\to +\infty$.
Poniamo
\[
  E = \lim_{M\to +\infty} S_M
    = \sum_{k=0}^{+\infty} \frac{\abs{z}^k}{k!}.
\]

Consideriamo ora un qualunque $\eps > 0 $, e scegliamo un $M$
(grazie alla definizione di limite $S_M \to E$) tale
che
\[
\sum_{k=M+1}^{+\infty} \frac{\abs{z}^k} {k!}
= E - S_M < \eps.
\]
Fissato $k\le M$ visto che $c(n,k)\to 1$
esiste $N_k > M$ tale che per ogni $n>N_k$
si abbia $1-c(n,k) < \eps$
(ricordiamo che $c(n,k)\le 1$).
Prendiamo allora
\[
  N=\max_{k=0}^M N_k
\]
cosicchè per ogni $n>N$ e per ogni $k\le M$ si avrà $1-c(n,k) < \eps$.
Allora, per ogni $n>N$
\begin{align*}
\abs{\sum_{k=0}^n \frac{z^k}{k!} - \enclose{1+\frac z n}^n}
&= \abs{\sum_{k=0}^n \enclose{\frac{z^k}{k!} - c(n,k)\frac{z^k}{k!}}}
= \abs{\sum_{k=0}^n  (1-c(n,k))\frac{z^k}{k!}} \\
&\le \sum_{k=0}^n  (1-c(n,k))\frac{\abs{z}^k}{k!} \\
&\le \sum_{k=0}^{N} \abs{1-c(n,k)} \frac{\abs{z}^k}{k!}
   + \sum_{k=N+1}^n \frac{\abs{z}^k}{k!} \\
&\le  \eps \sum_{k=0}^{+\infty} \frac{\abs{z}^k}{k!}
    + \sum_{k=N+1}^{+\infty} \frac{\abs{z}^k}{k!} \\
&\le \eps E + \eps
= \eps (E+1).
\end{align*}

Visto che $\eps>0$ era arbitrario abbiamo verificato
tramite la definizione che
\[
\sum_{k=0}^n \frac{z^k}{k!} - \enclose{1+\frac z n}^n \to 0
\]
cioè
\[
\lim_{n\to +\infty} \enclose{1+\frac z n}^n = \sum_{k=0}^{+\infty} \frac{z^k}{k!}.
\]
\end{proof}

Aver distinto le due definizioni di $e^z$ (tramite limite)
e di $\exp(z)$ (tramite somma della serie) è puramente strumentale.
C'è una unica funzione esponenziale che può essere definita in
un modo o nell'altro. Non ci si fissi quindi con l'identificare
le due diverse notazioni $e^z$ ed $\exp(z)$ con le due diverse definizioni.
Ogni testo avrà una sua definizione di funzione esponenziale che può
essere per certi versi arbitraria salvo poi ritrovare le proprietà
caratterizzanti di tale funzione.

\begin{theorem}[proprietà dell'esponenziale complesso]
Si ha:
\begin{enumerate}
\item
$\displaystyle \exp(0) = 1$;
\item
per ogni $z,w \in \CC$
\[
  \exp(z+w) = \exp(z) \cdot \exp(w);
\]
\item
per ogni $z\in \CC$ si ha $\exp(z) \neq 0$ e
\[
 \exp(-z) = \frac{1}{\exp(z)};
\]
\item la funzione $\exp\colon \CC \to \CC$ è (sequenzialmente) continua.
\end{enumerate}
\end{theorem}
%
\begin{proof}
\begin{enumerate}
\item
La proprietà $\exp(0)=1$ segue per verifica diretta (ricordiamo che $0^0=1$).

\item
Consideriamo la matrice infinita
\[
m_{k,j}  = \frac{z^k}{k!} \cdot \frac{w^j}{j!}.
\]
Allora da un lato
\begin{align*}
 \exp(z+w)
 &= \sum_{n=0}^{+\infty} \frac{(z+w)^n}{n!}\\
 &= \sum_{n=0}^{+\infty} \frac{1}{n!}\sum_{k=0}^n \frac{n!}{k!(n-k)!} z^k\cdot w^{n-k}\\
 &= \sum_{n=0}^{+\infty} \sum_{k=0}^n m_{k, n-k}
\end{align*}
e dall'altro
\begin{align*}
 \exp(z) \cdot \exp(w)
 &= \sum_{k=0}^{+\infty}\frac{z^k}{k!} \sum_{j=0}^{+\infty}\frac{w^j}{j!} \\
 &= \lim_{n\to+\infty} \sum_{k=0}^n \frac{z^k}{k!} \sum_{j=0}^n \frac{w^j}{j!} \\
 &= \lim_{n\to+\infty} \sum_{k=0}^n \sum_{j=0}^n m_{k,j}.
\end{align*}

In entrambi i casi stiamo dunque sommando tutti i termini della
matrice $m_{k,j}$ in un ordine diverso: nel primo caso stiamo associando i termini lungo le diagonali, nel secondo caso stiamo associando i termini
lungo le cornici quadrate.

Ma la serie $\sum m_{k,j}$ è assolutamente convergente e quindi
la sua somma non dipende dall'ordine in cui prendiamo gli addendi.
\item
Visto che
\[
  1 = \exp( 0) = \exp(z-z) = \exp(z) \cdot \exp(-z)
\]
ricaviamo che $\exp(z)\neq 0$ e $\exp(-z) =  1 / \exp(z)$.
\item
...
\end{enumerate}
\end{proof}
\end{comment}

\begin{comment}
\section{operatori $\Sigma$ e $\Delta$}

Sullo spazio vettoriale $V = \RR^\NN$ delle successioni
reali (o più in generale $V=\CC^\NN$ delle successioni complesse)
possiamo definire due
operatori lineari $\Sigma\colon V \to V$ e $\Delta\colon V \to V$
che sono gli operatori
che mandano una successione nella serie corrispondente (cioè nella successione
delle somme parziali) e l'operatore inverso che manda la successione
delle somme parziali nella successione dei corrispondenti termini
della serie.

Formalmente, per ogni successione $\vec a \in V$
definiamo $\Sigma \vec a \in V$ e $\Delta \vec a \in V$
come segue:
\begin{align*}
  \enclose{\Sigma \vec a}_n &= \sum_{k=0}^n a_k\\
  \enclose{\Delta \vec a}_n &=
  \begin{cases}
    a_n - a_{n-1} & \text{se $n>0$,}\\
    a_0 & \text{se $n=0$.}
  \end{cases}
\end{align*}
Verifichiamo che $\Delta \Sigma \vec a = \vec a$.
Se $n>0$
\[ \enclose{\Delta \Sigma \vec a}_n
 = \enclose{\Sigma \vec a}_n
 - \enclose{\Sigma \vec a}_{n-1}
 = \sum_{k=0}^n a_k - \sum_{k=0}^{n-1} a_k
 = a_n
\]
e se $n=0$:
\[
\enclose{\Delta \Sigma \vec a}_0
= \enclose{\Sigma \vec a}_0
= \sum_{k=0}^0 a_k
= a_0.
\]

Viceversa si ha anche $\Sigma \Delta \vec a = \vec a$
infatti:
\begin{align*}
\enclose{\Sigma \Delta \vec a}_n
&= \sum_{k=0}^n \enclose{\Delta \vec a}_k
= a_0 + \sum_{k=1}^n (a_k - a_{k-1}) \\
&= a_0 + \sum_{k=1}^n a_k - \sum_{k=1}^n a_{k-1}
= \sum_{k=0}^n a_k - \sum_{k=0}^{n-1} a_k
= a_n.
\end{align*}

Introduciamo anche l'operatore di traslazione $\tau \colon V\to V$
\[
(\tau \vec a)_n = a_{n+1}.
\]

\begin{theorem}[differenza del prodotto]
Se $\vec a$ e $\vec b$ sono successioni allora
\[
  \Delta (\vec a \cdot \vec b) = a \cdot \Delta b + \Delta a\cdot \tau b.
\]
\end{theorem}
%
\begin{proof}
Infatti per $n>0$ si ha
\[
\enclose{\Delta (\vec a \cdot \vec b)}_n
= a_n\cdot b_n - a_{n-1}\cdot b_{n-1}
= a_n \cdot b_n - a_n \cdot b_{n-1} + a_n \cdot b_{n-1} - a_{n-1}\cdot b_{n-1}
= a_n \cdot (\Delta \vec b)_n + (\Delta \vec a \cdot)_n \cdot b_{n-1}
\]
\end{proof}

\end{comment}
